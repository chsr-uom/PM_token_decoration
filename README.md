### Toward value-based care using process mining: a tutorial for cost aggregation and visualization across the entire colorectal cancer patient pathway.

This repository contains the python code associated with the paper. 

------------------------------------------------------------------------

#### ðŸ“– Abstract

**Background**: Amidst the climate crisis and persistent financial strain on the global healthcare system, it is imperative to prioritize cost estimation across the entire care continuum rather than single interventional procedures. Process mining for estimating aggregate costs, also referred to as cost mining, has shown promising initial results, but process maps remain descriptive and difficult to interpret. Methods that generate actionable information from real world data are therefore warranted.

**Methods**: We developed and tested a unique algorithm that leverages the powers of process mining to dynamically estimate total costs of care at the patient level, by incorporating and aggregating healthcare costs, and presenting these automatically on process maps as labels. We tested the feasibility of this method using a unique linked dataset of colorectal cancer pathways in Victoria, Australia covering 4,246 linked patient records collected between 2012-2020 and detailing their entire colorectal cancer pathway.

**Results**: The aggregated cost estimates generated by the algorithm enabled case-mix group comparisons and the exploration of inefficient, costly, or undesirable patient pathways. The combined registry data captures a total economic burden of $ 60,63M AUD, and per-patient costs ranged from $10,379 AUD to $41,643 AUD per stage of treatment. Admitted episodes were most costly, next to chemotherapy episodes. The analysis revealed large differences between stage D patients receiving specific chemotherapy regimens.

**Conclusion**: Cost mining is a feasible method for aggregating total patient level costs. This is particularly relevant to medical decision makers and healthcare policy because it not only uncovers cost sources but may also inform bundled payment initiatives.  The core limitations of this method relate to the current global dispersed and fractured health data infrastructure, which necessitates extensive manual linking of data. We provide suggestions for hospitals and policymakers looking to improve their health data infrastructure to enable real time patient level cost mining. 

------------------------------------------------------------------------

#### ðŸ” Repository content

``` bash
â”œâ”€â”€ token_decoration_custom.py    # this is the pm4py code for the token decoration of costs  
â”œâ”€â”€ using_token_decoration.R      # this is R code that details how to use decoration function in R
â”œâ”€â”€ commented_token_custom.py     # this is a commented version of the token decoration code
â””â”€â”€ README.md
```
------------------------------------------------------------------------

#### ðŸ”§ What is the required set-up?

The custom code contains two primary functions, get_decorations() and apply(), which are extensions of the PM4Py library for process mining. These functions are used to calculate decorations and apply them to a Petri net for visualization, with a focus on the performance measure obtained by token replay.

The functions are part of a custom algorithm which has been embedded in the PM4Py package due to the Object-Oriented Programming (OOP) nature of the codebase. The custom variant needs to be located at pm4py --> visualization --> petrinet --> variants --> token_decoration_custom in the package directory structure.

The OOP style coding of PM4Py allows parameters to be provided at a higher level and then passed down to the individual level where these functions operate. Thus, parameters such as the measure, activity key, and timestamp key are initially specified at a more general level in the codebase and are then utilized within these functions.

For executing this code, it's important to have the PM4Py package installed and understand the structure of the package. You should also have an appropriate process log and its corresponding Petri net, along with its initial and final markings. Finally, to correctly use these functions, understanding the role and effect of parameters, as well as the fundamentals of process mining and Petri nets, is required.
The codebase with this custom variant has been made available in the specified repository, providing direct access to the modifications and additions made for this specific use case.

------------------------------------------------------------------------

#### ðŸ’ª What are the functions?

The first function, get_decorations, is used to calculate metrics, referred to as decorations, for a given Petri net. These decorations, which include measures such as frequency and performance, serve to annotate the Petri net. The function takes as input the trace log of the process, the Petri net, initial and final markings, and other optional parameters. It then applies a sequence of operations: extracting variants from the log trace, applying token replay to align the log and model, computing single-element statistics, and finally aggregating these statistics.

The second function, apply, leverages the computed decorations to visualize the Petri net. If no aggregated statistics are provided, it invokes the get_decorations function to compute them. It then passes the net, markings, and decorations to a function in PM4Py, visualize.apply, to generate and return the final visualization of the Petri net.

Thus, the overall function of this script is to enrich and visualize Petri nets with performance information derived from process logs, facilitating better understanding and analysis of the process. We leverage this to provide costing decoration in process mining applies to the healthcare setting.


*Please get in touch with any questions or suggestions!*
